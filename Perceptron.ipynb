{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKbc3+zgixkrb72lZ2yIFv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "perceptron:nn의 한 종류"
      ],
      "metadata": {
        "id": "C2d-0s7zseLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "xor"
      ],
      "metadata": {
        "id": "UBIt3Fwrtyur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rAjOoTeigYWQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "perceptron은 1 layer 구조이기 때문에 fully connected layer하나를 선언한다."
      ],
      "metadata": {
        "id": "iVynZSnevm5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = torch.nn.Linear(2, 1, bias=True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "model = torch.nn.Sequential(linear, sigmoid).to(device)\n",
        "\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "for step in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # cost/loss function\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(step, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNG7XkJ7vyjb",
        "outputId": "2225dc7a-ea81-4884-e5f4-c3890f91454c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.7273973822593689\n",
            "100 0.6931476593017578\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931471824645996\n",
            "1300 0.6931471824645996\n",
            "1400 0.6931471824645996\n",
            "1500 0.6931471824645996\n",
            "1600 0.6931471824645996\n",
            "1700 0.6931471824645996\n",
            "1800 0.6931471824645996\n",
            "1900 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "2100 0.6931471824645996\n",
            "2200 0.6931471824645996\n",
            "2300 0.6931471824645996\n",
            "2400 0.6931471824645996\n",
            "2500 0.6931471824645996\n",
            "2600 0.6931471824645996\n",
            "2700 0.6931471824645996\n",
            "2800 0.6931471824645996\n",
            "2900 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "3100 0.6931471824645996\n",
            "3200 0.6931471824645996\n",
            "3300 0.6931471824645996\n",
            "3400 0.6931471824645996\n",
            "3500 0.6931471824645996\n",
            "3600 0.6931471824645996\n",
            "3700 0.6931471824645996\n",
            "3800 0.6931471824645996\n",
            "3900 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "4100 0.6931471824645996\n",
            "4200 0.6931471824645996\n",
            "4300 0.6931471824645996\n",
            "4400 0.6931471824645996\n",
            "4500 0.6931471824645996\n",
            "4600 0.6931471824645996\n",
            "4700 0.6931471824645996\n",
            "4800 0.6931471824645996\n",
            "4900 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "5100 0.6931471824645996\n",
            "5200 0.6931471824645996\n",
            "5300 0.6931471824645996\n",
            "5400 0.6931471824645996\n",
            "5500 0.6931471824645996\n",
            "5600 0.6931471824645996\n",
            "5700 0.6931471824645996\n",
            "5800 0.6931471824645996\n",
            "5900 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "6100 0.6931471824645996\n",
            "6200 0.6931471824645996\n",
            "6300 0.6931471824645996\n",
            "6400 0.6931471824645996\n",
            "6500 0.6931471824645996\n",
            "6600 0.6931471824645996\n",
            "6700 0.6931471824645996\n",
            "6800 0.6931471824645996\n",
            "6900 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "7100 0.6931471824645996\n",
            "7200 0.6931471824645996\n",
            "7300 0.6931471824645996\n",
            "7400 0.6931471824645996\n",
            "7500 0.6931471824645996\n",
            "7600 0.6931471824645996\n",
            "7700 0.6931471824645996\n",
            "7800 0.6931471824645996\n",
            "7900 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "8100 0.6931471824645996\n",
            "8200 0.6931471824645996\n",
            "8300 0.6931471824645996\n",
            "8400 0.6931471824645996\n",
            "8500 0.6931471824645996\n",
            "8600 0.6931471824645996\n",
            "8700 0.6931471824645996\n",
            "8800 0.6931471824645996\n",
            "8900 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "9100 0.6931471824645996\n",
            "9200 0.6931471824645996\n",
            "9300 0.6931471824645996\n",
            "9400 0.6931471824645996\n",
            "9500 0.6931471824645996\n",
            "9600 0.6931471824645996\n",
            "9700 0.6931471824645996\n",
            "9800 0.6931471824645996\n",
            "9900 0.6931471824645996\n",
            "10000 0.6931471824645996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmtRhJIPwMwh",
        "outputId": "51138944-c0be-44db-aa1a-920df3c63da7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hypothesis:  [[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]] \n",
            "Correct:  [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] \n",
            "Accuracy:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP(Multi Layer Perceptron) 에서 사용되는 backpropagation"
      ],
      "metadata": {
        "id": "5j_DbzDawwEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear1 = torch.nn.Linear(2, 2, bias=True)\n",
        "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
        "\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "for step in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # cost/loss function\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(step, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCQopSuBwQxC",
        "outputId": "d6f05948-f210-409c-d690-a5d07faf31bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.700675368309021\n",
            "100 0.6931769251823425\n",
            "200 0.6930182576179504\n",
            "300 0.6927666068077087\n",
            "400 0.6919799447059631\n",
            "500 0.6875231266021729\n",
            "600 0.6445480585098267\n",
            "700 0.480523943901062\n",
            "800 0.403169721364975\n",
            "900 0.3791578412055969\n",
            "1000 0.3687925338745117\n",
            "1100 0.36321818828582764\n",
            "1200 0.35979029536247253\n",
            "1300 0.3574887216091156\n",
            "1400 0.35584473609924316\n",
            "1500 0.3546162545681\n",
            "1600 0.35366523265838623\n",
            "1700 0.3529089391231537\n",
            "1800 0.3522937297821045\n",
            "1900 0.3517838418483734\n",
            "2000 0.3513548970222473\n",
            "2100 0.35098937153816223\n",
            "2200 0.3506741523742676\n",
            "2300 0.3503999710083008\n",
            "2400 0.3501589000225067\n",
            "2500 0.34994572401046753\n",
            "2600 0.3497559428215027\n",
            "2700 0.3495856523513794\n",
            "2800 0.3494322896003723\n",
            "2900 0.34929341077804565\n",
            "3000 0.3491669297218323\n",
            "3100 0.3490515351295471\n",
            "3200 0.3489457070827484\n",
            "3300 0.348848432302475\n",
            "3400 0.34875839948654175\n",
            "3500 0.3486751914024353\n",
            "3600 0.34859809279441833\n",
            "3700 0.3485260009765625\n",
            "3800 0.3484588861465454\n",
            "3900 0.34839606285095215\n",
            "4000 0.3483372926712036\n",
            "4100 0.3482822775840759\n",
            "4200 0.34823036193847656\n",
            "4300 0.3481813669204712\n",
            "4400 0.3481351137161255\n",
            "4500 0.3480914235115051\n",
            "4600 0.34805017709732056\n",
            "4700 0.34801095724105835\n",
            "4800 0.3479737639427185\n",
            "4900 0.3479384779930115\n",
            "5000 0.3479047417640686\n",
            "5100 0.347872793674469\n",
            "5200 0.347842276096344\n",
            "5300 0.3478130102157593\n",
            "5400 0.34778493642807007\n",
            "5500 0.34775838255882263\n",
            "5600 0.3477325439453125\n",
            "5700 0.3477080464363098\n",
            "5800 0.347684383392334\n",
            "5900 0.3476617932319641\n",
            "6000 0.34764015674591064\n",
            "6100 0.34761905670166016\n",
            "6200 0.3475992679595947\n",
            "6300 0.347579687833786\n",
            "6400 0.3475611209869385\n",
            "6500 0.3475431203842163\n",
            "6600 0.34752577543258667\n",
            "6700 0.34750896692276\n",
            "6800 0.3474927842617035\n",
            "6900 0.34747713804244995\n",
            "7000 0.34746187925338745\n",
            "7100 0.3474475145339966\n",
            "7200 0.34743309020996094\n",
            "7300 0.347419410943985\n",
            "7400 0.3474059998989105\n",
            "7500 0.3473931849002838\n",
            "7600 0.34738075733184814\n",
            "7700 0.3473685383796692\n",
            "7800 0.34735679626464844\n",
            "7900 0.3473455011844635\n",
            "8000 0.34733420610427856\n",
            "8100 0.34732332825660706\n",
            "8200 0.34731292724609375\n",
            "8300 0.3473026752471924\n",
            "8400 0.3472926616668701\n",
            "8500 0.34728288650512695\n",
            "8600 0.34727349877357483\n",
            "8700 0.3472645878791809\n",
            "8800 0.34725531935691833\n",
            "8900 0.3472467064857483\n",
            "9000 0.34723803400993347\n",
            "9100 0.3472297191619873\n",
            "9200 0.3472217321395874\n",
            "9300 0.3472136855125427\n",
            "9400 0.34720590710639954\n",
            "9500 0.34719836711883545\n",
            "9600 0.3471909165382385\n",
            "9700 0.3471839427947998\n",
            "9800 0.34717684984207153\n",
            "9900 0.34717005491256714\n",
            "10000 0.3471633195877075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ2IJYXEyOdl",
        "outputId": "82b6ae20-aa22-48bd-d188-649a38ce3f5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hypothesis:  [[5.9592456e-04]\n",
            " [4.9974442e-01]\n",
            " [9.9934798e-01]\n",
            " [5.0029904e-01]] \n",
            "Correct:  [[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]] \n",
            "Accuracy:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "learning_rate = 0.5\n",
        "batch_size = 10\n",
        "\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)\n",
        "\n",
        "w1 = torch.nn.Parameter(torch.Tensor(784, 30)).to(device)\n",
        "b1 = torch.nn.Parameter(torch.Tensor(30)).to(device)\n",
        "w2 = torch.nn.Parameter(torch.Tensor(30, 10)).to(device)\n",
        "b2 = torch.nn.Parameter(torch.Tensor(10)).to(device)\n",
        "\n",
        "torch.nn.init.normal_(w1)\n",
        "torch.nn.init.normal_(b1)\n",
        "torch.nn.init.normal_(w2)\n",
        "torch.nn.init.normal_(b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAbfW-LLyeol",
        "outputId": "60708d77-027c-4ea2-eb83-6ba29a07ec23"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 83583549.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24661175.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 35278320.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2577530.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-1.3111,  0.6142, -0.6474,  0.1758, -0.2125, -0.2396, -0.4764,  1.2709,\n",
              "         1.1475,  0.4063], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    #  sigmoid function\n",
        "    return 1.0 / (1.0 + torch.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    # derivative of the sigmoid function\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)[:1000]\n",
        "Y_test = mnist_test.test_labels.to(device)[:1000]\n",
        "i = 0\n",
        "while not i == 10000:\n",
        "    for X, Y in data_loader:\n",
        "        i += 1\n",
        "\n",
        "        # forward\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = torch.zeros((batch_size, 10)).scatter_(1, Y.unsqueeze(1), 1).to(device)    # one-hot\n",
        "        l1 = torch.add(torch.matmul(X, w1), b1)\n",
        "        a1 = sigmoid(l1)\n",
        "        l2 = torch.add(torch.matmul(a1, w2), b2)\n",
        "        y_pred = sigmoid(l2)\n",
        "\n",
        "        diff = y_pred - Y\n",
        "\n",
        "        # Backpropagation (chain rule)\n",
        "        d_l2 = diff * sigmoid_prime(l2)\n",
        "        d_b2 = d_l2\n",
        "        d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_l2)\n",
        "\n",
        "        d_a1 = torch.matmul(d_l2, torch.transpose(w2, 0, 1))\n",
        "        d_l1 = d_a1 * sigmoid_prime(l1)\n",
        "        d_b1 = d_l1\n",
        "        d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_l1)\n",
        "\n",
        "        #weight update(minimize task)\n",
        "        w1 = w1 - learning_rate * d_w1\n",
        "        b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
        "        w2 = w2 - learning_rate * d_w2\n",
        "        b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            l1 = torch.add(torch.matmul(X_test, w1), b1)\n",
        "            a1 = sigmoid(l1)\n",
        "            l2 = torch.add(torch.matmul(a1, w2), b2)\n",
        "            y_pred = sigmoid(l2)\n",
        "            acct_mat = torch.argmax(y_pred, 1) == Y_test\n",
        "            acct_res = acct_mat.sum()\n",
        "            print(acct_res.item())\n",
        "\n",
        "        if i == 10000:\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O-8YB4ZysJ7",
        "outputId": "e87ce8ee-94c5-49ba-dc74-a74c617254ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:71: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "829\n",
            "869\n",
            "884\n",
            "876\n",
            "893\n",
            "901\n",
            "900\n",
            "909\n",
            "906\n",
            "897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
        "\n",
        "linear1 = torch.nn.Linear(2, 2, bias=True)\n",
        "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
        "\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "for step in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # cost/loss function\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(step, cost.item())\n",
        "\n",
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM8PiVdb0FhN",
        "outputId": "8358a900-1047-4e81-d6e8-181acc1afc6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.697848916053772\n",
            "100 0.6929659247398376\n",
            "200 0.6907414197921753\n",
            "300 0.6747615337371826\n",
            "400 0.589339554309845\n",
            "500 0.47371572256088257\n",
            "600 0.20856642723083496\n",
            "700 0.08191096037626266\n",
            "800 0.04722043126821518\n",
            "900 0.032599303871393204\n",
            "1000 0.024723289534449577\n",
            "1100 0.01984424889087677\n",
            "1200 0.016540445387363434\n",
            "1300 0.01416158489882946\n",
            "1400 0.012370157055556774\n",
            "1500 0.01097421906888485\n",
            "1600 0.009856796823441982\n",
            "1700 0.008942730724811554\n",
            "1800 0.008181538432836533\n",
            "1900 0.007538053207099438\n",
            "2000 0.006987144239246845\n",
            "2100 0.006510309409350157\n",
            "2200 0.00609360309317708\n",
            "2300 0.005726422183215618\n",
            "2400 0.00540050258859992\n",
            "2500 0.0051092542707920074\n",
            "2600 0.004847477190196514\n",
            "2700 0.004610976669937372\n",
            "2800 0.004396185744553804\n",
            "2900 0.004200359806418419\n",
            "3000 0.004021056927740574\n",
            "3100 0.0038563061971217394\n",
            "3200 0.003704366274178028\n",
            "3300 0.0035638781264424324\n",
            "3400 0.0034335157833993435\n",
            "3500 0.00331228063441813\n",
            "3600 0.0031992383301258087\n",
            "3700 0.0030936184339225292\n",
            "3800 0.0029946479480713606\n",
            "3900 0.002901787869632244\n",
            "4000 0.0028144866228103638\n",
            "4100 0.0027322261594235897\n",
            "4200 0.0026545694563537836\n",
            "4300 0.002581214066594839\n",
            "4400 0.0025117695331573486\n",
            "4500 0.002445918507874012\n",
            "4600 0.0023834039457142353\n",
            "4700 0.0023239869624376297\n",
            "4800 0.0022674270439893007\n",
            "4900 0.0022135842591524124\n",
            "5000 0.002162178745493293\n",
            "5100 0.002113087335601449\n",
            "5200 0.002066141227260232\n",
            "5300 0.002021260792389512\n",
            "5400 0.0019782567396759987\n",
            "5500 0.0019370319787412882\n",
            "5600 0.0018975023413076997\n",
            "5700 0.0018595231231302023\n",
            "5800 0.001823041820898652\n",
            "5900 0.001787922577932477\n",
            "6000 0.0017541262786835432\n",
            "6100 0.0017216084524989128\n",
            "6200 0.001690248609520495\n",
            "6300 0.0016600043745711446\n",
            "6400 0.0016308182384818792\n",
            "6500 0.0016026345547288656\n",
            "6600 0.0015754009364172816\n",
            "6700 0.001549056963995099\n",
            "6800 0.0015236146282404661\n",
            "6900 0.001498923054896295\n",
            "7000 0.0014750789850950241\n",
            "7100 0.0014519395772367716\n",
            "7200 0.0014295175205916166\n",
            "7300 0.001407769974321127\n",
            "7400 0.0013867029920220375\n",
            "7500 0.0013662164565175772\n",
            "7600 0.0013463526265695691\n",
            "7700 0.001327011501416564\n",
            "7800 0.0013082667719572783\n",
            "7900 0.0012900176225230098\n",
            "8000 0.0012722499668598175\n",
            "8100 0.0012550146784633398\n",
            "8200 0.0012381823034957051\n",
            "8300 0.0012218019692227244\n",
            "8400 0.0012058637803420424\n",
            "8500 0.001190332928672433\n",
            "8600 0.0011751907877624035\n",
            "8700 0.0011604097671806812\n",
            "8800 0.001146037015132606\n",
            "8900 0.0011320057092234492\n",
            "9000 0.0011182529851794243\n",
            "9100 0.0011048848973587155\n",
            "9200 0.0010918115731328726\n",
            "9300 0.0010790553642436862\n",
            "9400 0.0010666085872799158\n",
            "9500 0.0010544053511694074\n",
            "9600 0.0010424747597426176\n",
            "9700 0.0010308378841727972\n",
            "9800 0.0010194319766014814\n",
            "9900 0.0010082843946292996\n",
            "10000 0.0009974150452762842\n",
            "\n",
            "Hypothesis:  [[1.2836227e-03]\n",
            " [9.9910635e-01]\n",
            " [9.9910694e-01]\n",
            " [9.1680849e-04]] \n",
            "Correct:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:  1.0\n"
          ]
        }
      ]
    }
  ]
}